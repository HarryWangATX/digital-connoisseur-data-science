{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"colab":{"name":"index.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"Um3cn7TMvjDH"},"source":["#hide\n","from digital_connoisseur.dataloader import *"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bNv2jre7vjDK"},"source":["# digital_connoisseur\n","\n","> This package contains tools used to work with on the digital connoisseur project. We can use it to load and preprocess the data."]},{"cell_type":"markdown","metadata":{"id":"AGEeOcBNvjDL"},"source":["## How to use"]},{"cell_type":"markdown","metadata":{"id":"VU-QWm1dvjDL"},"source":["Using the module to load the data is quite simple. If you are on your local machine, you can use the following code to obtain the data:"]},{"cell_type":"code","metadata":{"id":"VpzLrI-5vjDM"},"source":["dls = get_dls()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hkkYTX9AvjDM"},"source":["If you are on google colab, simply tell the function that you are on colab. It will attempt to obtain the data from google drive. For this to work, you should have a zip file of the data stored in the top level of your drive, under the name `dc-data.zip`."]},{"cell_type":"code","metadata":{"id":"m3RlhRtKvjDM"},"source":["dls = get_dls(colab=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CFaV6NYDvjDN"},"source":["When get_dls opens the data, it will attempt to perform image segmentation, which is a lengthy process. If get_dls has done this before in the same runtime, it will skip this step. If it hasn't done it before, it will check to see if image segments have been generated before. If they have, it will ask for confirmation before rerunning the segmentation process. If they haven't, it will go ahead and run the segmentation process.\n","\n","### Arguments\n","\n","`get_dls` has four arguments, all of which have default values: `colab=False, force_reset=False, path_to_data=None, skip_segmentation=False`.\n","\n","`colab` determines whether you are on google colab; if you're on colab, it attempts to load the data from a zip file. If you're not, it just asks for the path to the data.\n","\n","`force_reset`, when set to `True`, forces `get_dls` to redo all of the steps it's done before. Ordinarily, `get_dls` skips over steps it has already completed in the same runtime, such as finding the data and performing segmentation. \n","\n","`path_to_data` can be used to specify a path to the data, without having to enter it into a prompt. This is useful on google colab, as it allows you to bypass the steps of finding/unzipping a zip file and instead goes straight to the folder you specified.\n","\n","`skip_segmentation`, when set to True, skips the segmentation step. This should only be used if segmentation has been performed at least once before on the data."]},{"cell_type":"markdown","metadata":{"id":"0ZdUjV-XvlYQ"},"source":["####Getting the holdout set\n","\n","In addition to obtaining the data via `get_dls()`, you can also obtain a special holdout set, with a 0% overlap guarantee. Once you have a model trained, run this code to validate it on a holdout set (assuming the model is called `learn`):"]},{"cell_type":"code","metadata":{"id":"43AlhivP_1UZ"},"source":["dl_holdout = learn.dls.test_dl(holdout_set, with_labels=True)\n","results = learn.validate(dl=dl_holdout)\n","print(results)"],"execution_count":null,"outputs":[]}]}