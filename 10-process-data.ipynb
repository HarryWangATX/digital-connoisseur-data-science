{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"colab":{"name":"10-process-data.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"P4oB-eUFXrnr"},"source":["#default_exp dataloader"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xb8GFoQ5Xrnv"},"source":["# 10-process-data: Importing, cleaning, testing, and saving\n","\n","**Purpose** The purpose of this notebook is to load, clean, and save the data.  The data should also be tested upon entry and exit to ensure that all of its variables have values that are expected.  You may also form a train and test set here if desired.\n","\n","**A note on imputation**: If the data requires parameterized imputation and scikit-learn is the expected methodology of interest, evaluate whether performing imputation here or as a pipeline step would be most valuable and helpful."]},{"cell_type":"markdown","metadata":{"id":"qkgyOyncXrnw"},"source":["## YOUR ATTENTION, PLEASE\n","\n","This notebook is built into a module by nbdev. If you are making changes to it, you should make sure you have nbdev installed (`pip install nbdev`). When your changes are completed, you can then call `nbdev_build_lib` from the root directory of the repository. This will build the notebook into a library, stored in the folder `digital_connoisseur`. "]},{"cell_type":"markdown","metadata":{"id":"49HncOKrXrnw"},"source":["*If you're using colab, run this cell to ensure you are able to import fastai, then restart the runtime when prompted.*"]},{"cell_type":"code","metadata":{"id":"g3y9KoWBXrnw"},"source":["#hide\n","!pip install --upgrade fastai fastcore"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FSqH_9v3Xrnx"},"source":["#### Helpful packages and preliminaries"]},{"cell_type":"code","metadata":{"id":"lduFFVasXrnx"},"source":["#export\n","#Import modules for data access and processing\n","try:\n","    import pandas as pd\n","except:\n","    print(\"pandas is unavailable\")\n","try:\n","    import numpy as np\n","except:\n","    print(\"numpy is unavailable\")\n","try:\n","    from fastai.vision.all import *\n","except:\n","    print(\"fastai.vision.all is unavailable\")\n","try:\n","    from google.colab import drive\n","except:\n","    print(\"google.colab is unavailable\")\n","try:\n","  from PIL import Image\n","except:\n","  print('PIL is unavailable')\n","try:\n","  from tqdm import tqdm\n","except:\n","  print('tqdm is unavailable')\n","from os import system"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lEm1KhWKXrny"},"source":["### Find the data\n","\n","If you're working on a local machine, you can run the top cell and tell it where your data folder is. If, like me, you are doing this from colab, you'll need to upload the data to google drive. Compress the data into a zip file, title it `dc-data.zip`, upload it to drive (don't put it in any folders), then run the cell; it will ask you where the zip file is, copy the zip file into the current working directory, and then unzip the folder.  Also, in order to be able to access other files in the repository, you can upload the repository to google drive, keep the drive mounted, and use that. You will need to `cd` to the directory where the repository is on Google Drive."]},{"cell_type":"code","metadata":{"id":"TOLZ01auXrny"},"source":["#export\n","### IF ON LOCAL MACHINE ###\n","\n","def get_path_local():\n","    return input('Enter path to data\\n> ')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gpA6DcqVXrnz"},"source":["#export\n","### IF USING GOOGLE DRIVE ###\n","\n","def get_path_zip():\n","    path_to_zip = input('Enter path to zip file\\n>')\n","    path_to_folder = input('Where do you want it stored?\\n>')\n","\n","    print(f'Moving zip file from {path_to_zip} to {path_to_folder}/dc-data.zip...')\n","    system(f'cp \"{path_to_zip}\" \"{path_to_folder}/dc-data.zip\"')\n","    \n","    copied_zip = f'{path_to_folder}/dc-data.zip'\n","\n","    print(f'Unzipping zip file at {copied_zip}...')\n","    system(f'unzip {copied_zip} -d {path_to_folder}')\n","\n","    print(f'Done. Data should be at {path_to_folder}/dc-data.')\n","\n","    return f'{path_to_folder}/dc-data'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KXoT0tcMXrnz"},"source":["### Get data into `DataLoader`\n","\n","The purpose of the above scripts was to locate where the data is stored. Now, we need to actually load it, using `DataLoader`. This part of the pipeline is subject to change, as we revise and improve our data processing."]},{"cell_type":"code","metadata":{"id":"iYfWmvP-Xrnz"},"source":["#export\n","# define the functions we need\n","# make the segment:\n","def make_segment(left, up, std_length, std_width, img):\n","    width, height = img.size\n","    right = left + std_width\n","    below = up + std_length\n","\n","    right_flag = False\n","    below_flag = False\n","\n","    if right > width:\n","        right = width\n","        left = width - std_width\n","        right_flag = True\n","\n","    if below > height:\n","        below = height\n","        up = below - std_length\n","        below_flag = True\n","\n","    box=(left, up, right, below)\n","    sample_img = img.crop(box)\n","    return sample_img, right_flag, below_flag\n","\n","\n","# get the left and up\n","def get_left_up(right_flag,below_flag,pre_left,pre_up,overlap):\n","    if right_flag==True and below_flag==False :\n","        # reach the right edge\n","        next_left=0\n","        nex_up=pre_up+overlap\n","\n","    if right_flag==False and below_flag==True :\n","        # reach the below edge\n","        next_left=pre_left+overlap\n","        nex_up=pre_up\n","\n","    if right_flag==True and below_flag==True:\n","        #reach both side\n","        next_left = -100\n","        nex_up = -100\n","\n","    if right_flag==False and below_flag==False:\n","        next_left = pre_left + overlap\n","        nex_up = pre_up\n","\n","    return next_left,nex_up\n","\n","    #get precent of white space of sample image:\n","def get_white_precent(sample_img,std_width,std_height):\n","    sample_img=list(sample_img.getdata())\n","    count=0\n","\n","    for x in sample_img:\n","        if x[0]==255 and x[1]==255 and x[2]==255:\n","            count=count+1\n","\n","    result=int((count/(std_width*std_height))*100)\n","\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7eZUoa9EXrn0"},"source":["#export\n","imagesAndLabels = None\n","imagesAndLabelsDict = None\n","\n","def set_labels_dict(path_to_data):\n","    global imagesAndLabels\n","    global imagesAndLabelsDict\n","    \n","    imagesAndLabels = pd.read_csv(path_to_data+'/MocheThemeRollouts.csv')\n","    imagesAndLabelsDict = {}\n","\n","    # Read the images and labels into the dictionary\n","    for rownum in range(len(imagesAndLabels)):\n","      image = imagesAndLabels.iloc[rownum,0]\n","      label = imagesAndLabels.iloc[rownum,1].strip()\n","      imagesAndLabelsDict[image] = label\n","\n","# Define a function that looks up the image name (minus the \".jpg\" suffix) in the dictionary\n","def label_func(filename):\n","  strf = str(filename)\n","  simplefilename = strf[strf.rindex('/')+1:-4]\n","  img_id = int(simplefilename)\n","  return imagesAndLabelsDict[img_id]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_MnlYu1bXrn0"},"source":["#export\n","\n","# define attribute\n","std_length = 178  # size we want\n","std_width = 178\n","overlap = int(178 / 2)\n","\n","def slice_image(img, path_to_data): #This function cuts up each image into overlapping squares\n","  strf = str(img)\n","  img_id = strf[strf.rindex('/')+1:-4]\n","  image = Image.open(img)\n","  # cut the image\n","  left = 0\n","  up = 0\n","  while left != -100:\n","    sample_img, right_flag, below_flag = make_segment(left, up, std_length, std_width, image)\n","    # action to sample img:\n","    wh_precent = get_white_precent(sample_img, std_width, std_length)\n","        \n","    theme = label_func(img)\n","    folder = theme.replace(' ', '')\n","        \n","    if wh_precent < 70:\n","      filepath = path_to_data + '/' + folder + \"/\" + 'xxseg-' + str(img_id) + \"-\" +str(int(left)) + \"-\" + str(int(up)) + \"-\" + str(wh_precent) + \".jpg\"\n","      try:\n","        sample_img.save(filepath)\n","      except:\n","        system(f'mkdir {path_to_data}/{folder}')\n","        sample_img.save(filepath)\n","        \n","    # get next left and up:\n","    pre_left = left\n","    pre_up = up\n","    left, up = get_left_up(right_flag, below_flag, left, up, overlap)\n","\n","def segment_images(path_to_data): #This segments each image and saves the segments to disk\n","  print('Removing old subdirectories...')\n","  system(f'rm -R -- {path_to_data}/*/')\n","  print('Performing segmentation and saving to new subdirectories...')\n","  try:\n","    for img in tqdm(get_image_files(path_to_data,recurse=False),desc=\"Segmenting images\"):\n","      slice_image(img,path_to_data)\n","  except:\n","    for img in get_image_files(path_to_data,recurse=False):\n","      slice_image(img,path_to_data)\n","  print('Done.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ZbZaIIXXrn1"},"source":["#export\n","from os import sep\n","from random import shuffle\n","\n","def get_overlap(img_1, img_2):\n","  \"\"\"Get whether img_1 and img_2 overlap with each other.\n","  The arguments should be the filenames, not the actual images.\"\"\"\n","  img_1_split = img_1.split('-')\n","  img_2_split = img_2.split('-')\n","  id1 = img_1_split[1]\n","  id2 = img_2_split[1]\n","  if id1 != id2:\n","    return False\n","  x1 = int(img_1_split[2])\n","  x2 = int(img_2_split[2])\n","  y1 = int(img_1_split[3])\n","  y2 = int(img_2_split[3])\n","  if (abs(x1-x2) < std_width) and (abs(y1-y2) < std_length):\n","    return True\n","  return False\n","\n","training_set = []\n","holdout_set = []\n","\n","def get_segmented_image_files(path_to_data):\n","  files = get_image_files(path_to_data)\n","  segmented_files = []\n","  for image in files:\n","    if 'xxseg' in str(image): #segmented images all contain the string \"xxseg\" in the title, to identify them\n","      segmented_files.append(image)\n","  return segmented_files\n","\n","def sort_segmented_image_files(path_to_data):\n","  \"\"\"Sort segmented images into training_set and holdout_set\"\"\"\n","  global training_set, holdout_set\n","  files = get_image_files(path_to_data)\n","  segmented_files = get_segmented_image_files(path_to_data)\n","  shuffle(segmented_files)\n","\n","  holdout_ids = {} # IDs of pictures we are holding out, sorted by label\n","  holdout_segments = {} # Names of segments we are holding out, sorted by label\n","\n","  for img in segmented_files:\n","    full_path = str(img)\n","    path_split = full_path.split(os.sep)\n","    name = path_split[-1]\n","    label = path_split[-2]\n","\n","    if label not in holdout_ids.keys():\n","      holdout_ids[label] = None\n","\n","    if label not in holdout_segments.keys():\n","      holdout_segments[label] = []\n","\n","    if label == 'BadmintonTheme' or label == 'RevoltoftheObjects':\n","      if len(holdout_segments[label]) < 75:\n","        holdout_segments[label].append(img)\n","      else:\n","        overlap = False\n","        for holdout_img in holdout_segments[label]:\n","          img_name = str(holdout_img).split(os.sep)[-1]\n","          if get_overlap(name, img_name):\n","            overlap = True\n","        if not overlap:\n","          training_set.append(img)\n","    \n","    else:\n","      id = name.split('-')[1]\n","      if holdout_ids[label] == None:\n","        holdout_ids[label] = id\n","      \n","      if holdout_ids[label] == id:\n","        holdout_segments[label].append(img)\n","      else:\n","        training_set.append(img)\n","\n","  for label in holdout_segments.keys():\n","    holdout_set.extend(holdout_segments[label])\n","\n","def get_training_files(path_to_data):\n","  return training_set\n","\n","def get_holdout_files(path_to_data):\n","  return holdout_set"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3MmSbnA_oERz"},"source":["#hide\n","#Use this debugging code to check for overlaps between training and holdout sets\n","for img in tqdm(training_set, desc=\"Checking for overlaps\"):\n","  for holdout_img in holdout_set:\n","    img_name = str(img).split(os.sep)[-1]\n","    holdout_name = str(holdout_img).split(os.sep)[-1]\n","    if get_overlap(img_name, holdout_name):\n","      print(str(img), str(holdout_img))\n","    assert not get_overlap(img_name, holdout_name)\n","print('\\nNo overlaps detected')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LNgM7RohqbBC"},"source":["#hide\n","# Use this debugging code to check how many of each label are in the training and holdout sets\n","label_counts = {}\n","for img in holdout_set:\n","  label = str(img).split(os.sep)[-2]\n","  try:\n","    label_counts[label] = label_counts[label] + 1\n","  except KeyError:\n","    label_counts[label] = 1\n","\n","print(label_counts)\n","\n","label_counts = {}\n","for img in training_set:\n","  label = str(img).split(os.sep)[-2]\n","  try:\n","    label_counts[label] = label_counts[label] + 1\n","  except KeyError:\n","    label_counts[label] = 1\n","\n","print(label_counts)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TxQxXCImXrn1"},"source":["#export\n","#these are global that help get_dls know what work it's already done.\n","global_path_to_data = None\n","already_set_labels = False\n","already_segmented = False\n","already_sorted = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_QVq-QuHXrn2"},"source":["#export\n","\n","def get_dls(colab=False, force_reset=False, path_to_data=None, skip_segmentation=False):\n","  global global_path_to_data\n","  global already_set_labels\n","  global already_segmented\n","  global already_sorted\n","\n","  if force_reset:\n","    global_path_to_data = None\n","    already_set_labels = False\n","    already_segmented = False\n","    already_sorted = False\n","\n","  if skip_segmentation:\n","    print('Skipping segmentation.')\n","    print(\"Errors will be thrown if segmentation hasn't already been performed.\")\n","    already_segmented = True\n","\n","  if path_to_data:\n","    global_path_to_data = path_to_data\n","\n","  if global_path_to_data == None:\n","    if colab:\n","        path_to_data = get_path_zip()\n","        global_path_to_data = path_to_data\n","    else:\n","        path_to_data = get_path_local()\n","        global_path_to_data = path_to_data\n","  else:\n","    path_to_data = global_path_to_data\n","      \n","  path = Path(path_to_data)\n","\n","  if not already_set_labels: \n","    set_labels_dict(path_to_data)\n","    \n","  if not already_segmented:\n","    segmented_images = get_segmented_image_files(path_to_data)\n","\n","    if len(segmented_images) != 0:\n","      print('Segmentation seems to have already been performed on this data.')\n","      repeat_segmentation = input('Do you want to do it again? y/[n]\\n> ')\n","      if repeat_segmentation != 'y' and repeat_segmentation != 'Y':\n","        already_segmented = True\n","    else:\n","      already_segmented = False\n","\n","  if not already_segmented:\n","    segment_images(path_to_data)\n","    already_segmented = True\n","\n","  if not already_sorted:\n","    sort_segmented_image_files(path_to_data)\n","\n","  print('Constructing DataBlock...')\n","  drawings = DataBlock(\n","      blocks=(ImageBlock, CategoryBlock), \n","      get_items=get_training_files, \n","      splitter=RandomSplitter(valid_pct=0.2, seed=42),\n","      get_y=parent_label,\n","      item_tfms=Resize(224),\n","      batch_tfms=Rotate(draw=lambda x: x.new_empty(x.size(0)).uniform_(-180, 180))\n","  )\n","\n","  print('Done.')\n","  return drawings.dataloaders(path)"],"execution_count":null,"outputs":[]}]}